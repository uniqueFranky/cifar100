"""
åˆ†å¸ƒå¼è®­ç»ƒå¯¹æ¯”å®éªŒæ‰¹é‡è„šæœ¬
æŒ‰ç…§æ§åˆ¶å˜é‡æ³•è®¾è®¡çš„5ä¸ªå®éªŒç»„ï¼Œæ¯ç»„ç»“æœä¿å­˜åœ¨ç‹¬ç«‹æ–‡ä»¶å¤¹ä¸­

å®éªŒç»„è®¾è®¡ï¼š
1. è®­ç»ƒæ¨¡å¼ä¸ç¡¬ä»¶é…ç½®ç»¼åˆå¯¹æ¯”
2. æ¨¡å‹å¤æ‚åº¦åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼ä¸‹çš„æ€§èƒ½å½±å“
3. æ•°æ®åŠ è½½å™¨å‚æ•°åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼ä¸‹çš„ä¼˜åŒ–æ•ˆæœ
4. æ‰¹å¤„ç†å¤§å°åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼å’Œç¡¬ä»¶é…ç½®ä¸‹çš„å½±å“
5. æµæ°´çº¿å¹¶è¡Œchunkså‚æ•°ä¼˜åŒ–

ä½¿ç”¨æ–¹å¼:
    python batch_train.py --experiment all          # è¿è¡Œæ‰€æœ‰å®éªŒç»„
    python batch_train.py --experiment 1            # è¿è¡Œå®éªŒç»„1
    python batch_train.py --experiment 1,3,5        # è¿è¡ŒæŒ‡å®šçš„å¤šä¸ªå®éªŒç»„
    python batch_train.py --experiment all --epochs 20  # æ‰€æœ‰å®éªŒä½†å‡å°‘epochs
"""

import subprocess
import os
import sys
import time
import json
from datetime import datetime
from itertools import product
from typing import List, Dict, Any, Optional
import argparse


class ExperimentGroup:
    """å®éªŒç»„å®šä¹‰"""
    
    def __init__(self, name: str, description: str, config: Dict[str, List[Any]], 
                 control_variables: str, comparison_focus: str):
        self.name = name
        self.description = description
        self.config = config
        self.control_variables = control_variables
        self.comparison_focus = comparison_focus
    
    def get_safe_name(self) -> str:
        """è·å–æ–‡ä»¶ç³»ç»Ÿå®‰å…¨çš„åç§°"""
        return self.name.lower().replace(' ', '_').replace('/', '_').replace('vs', 'vs')


class TrainingScheduler:
    """è®­ç»ƒä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self, base_dir: str = './experiments'):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
        
        self.experiment_groups = self._define_experiment_groups()
        self.results = {}
        
    def _define_experiment_groups(self) -> Dict[int, ExperimentGroup]:
        """å®šä¹‰æ‰€æœ‰å®éªŒç»„"""
        groups = {}
        
        # å®éªŒç»„1ï¼šè®­ç»ƒæ¨¡å¼ä¸ç¡¬ä»¶é…ç½®ç»¼åˆå¯¹æ¯”
        groups[1] = ExperimentGroup(
            name="Training Mode and Hardware Configuration Comparison",
            description="å…¨é¢æ¯”è¾ƒä¸åŒè®­ç»ƒæ¨¡å¼(single/dp/ddp/mp)åœ¨ä¸åŒç¡¬ä»¶é…ç½®(1å¡/2å¡/4å¡)ä¸‹çš„æ€§èƒ½è¡¨ç°",
            config={
                'mode': ['single', 'dp', 'ddp', 'mp', 'hp'],
                'model': ['resnet50'],
                'batch_size': [128],
                'epochs': [30],
                'dataset': ['cifar100'],
                'gpu_ids': [[1], [1, 2], [1, 2, 3, 4]],
                'num_workers': [2],
                'prefetch_factor': [1],
                'chunks': [0, 32]
            },
            control_variables="æ¨¡å‹æ¶æ„(ResNet50)ã€æ‰¹å¤„ç†å¤§å°(128)ã€æ•°æ®åŠ è½½å‚æ•°(workers=2, prefetch=1)",
            comparison_focus="è®­ç»ƒæ¨¡å¼(single/dp/ddp/mp/pp) Ã— ç¡¬ä»¶é…ç½®(1å¡/2å¡/4å¡)çš„æ€§èƒ½çŸ©é˜µå¯¹æ¯”"
        )

        # å®éªŒç»„2ï¼šæ¨¡å‹å¤æ‚åº¦åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼ä¸‹çš„æ€§èƒ½å½±å“
        groups[2] = ExperimentGroup(
            name="Model Complexity Impact Across Training Modes",
            description="æµ‹è¯•ä¸åŒå¤æ‚åº¦æ¨¡å‹(ResNet18/34/50)åœ¨å•æœºè®­ç»ƒå’Œåˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼ä¸‹çš„æ€§èƒ½å·®å¼‚å’Œæ‰©å±•æ€§",
            config={
                'mode': ['single', 'ddp'],
                'model': ['resnet18', 'resnet34', 'resnet50'],
                'batch_size': [128],
                'epochs': [30],
                'dataset': ['cifar100'],
                'gpu_ids': [[1], [1, 2, 3, 5]],
                'num_workers': [2],
                'prefetch_factor': [1],
                'chunks': [0]
            },
            control_variables="æ‰¹å¤„ç†å¤§å°(128)ã€æ•°æ®åŠ è½½å‚æ•°(workers=2, prefetch=1)ã€ç¡¬ä»¶é…ç½®å¯¹æ¯”(1å¡vs4å¡)",
            comparison_focus="æ¨¡å‹å¤æ‚åº¦(ResNet18/34/50) Ã— è®­ç»ƒæ¨¡å¼(single/ddp) Ã— ç¡¬ä»¶é…ç½®(1å¡/4å¡)"
        )
        
        # å®éªŒç»„3ï¼šæ•°æ®åŠ è½½å™¨å‚æ•°åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼ä¸‹çš„ä¼˜åŒ–æ•ˆæœ
        groups[3] = ExperimentGroup(
            name="DataLoader Optimization Across Training Modes",
            description="ç³»ç»Ÿæ€§æµ‹è¯•ä¸åŒæ•°æ®åŠ è½½workeræ•°é‡(0-16)åœ¨å•æœºå’Œåˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼ä¸‹å¯¹è®­ç»ƒæ€§èƒ½çš„å½±å“",
            config={
                'mode': ['single', 'ddp'],
                'model': ['resnet50'],
                'batch_size': [128],
                'epochs': [30],
                'dataset': ['cifar100'],
                'gpu_ids': [[1], [1, 2, 3, 5]],
                'num_workers': [0, 1, 2, 4, 8, 16],
                'prefetch_factor': [1],
                'chunks': [0]
            },
            control_variables="æ¨¡å‹æ¶æ„(ResNet50)ã€æ‰¹å¤„ç†å¤§å°(128)ã€ç¡¬ä»¶é…ç½®å¯¹æ¯”(1å¡vs4å¡)",
            comparison_focus="æ•°æ®åŠ è½½workeræ•°é‡(0/1/2/4/8/16) Ã— è®­ç»ƒæ¨¡å¼(single/ddp) Ã— ç¡¬ä»¶é…ç½®(1å¡/4å¡)"
        )
        
        # å®éªŒç»„4ï¼šæ‰¹å¤„ç†å¤§å°åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼å’Œç¡¬ä»¶é…ç½®ä¸‹çš„å½±å“
        groups[4] = ExperimentGroup(
            name="Batch Size Impact Across Training Modes and Hardware",
            description="åˆ†æä¸åŒæ‰¹å¤„ç†å¤§å°(64/128/256)åœ¨å•æœºå’Œåˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æ€§èƒ½è¡¨ç°å’Œå†…å­˜ä½¿ç”¨æ•ˆç‡",
            config={
                'mode': ['single', 'ddp'],
                'model': ['resnet50'],
                'batch_size': [32, 64, 128, 256],
                'epochs': [30],
                'dataset': ['cifar100'],
                'gpu_ids': [[1], [1, 2, 3, 5]],
                'num_workers': [2],
                'prefetch_factor': [1],
                'chunks': [0]
            },
            control_variables="æ¨¡å‹æ¶æ„(ResNet50)ã€æ•°æ®åŠ è½½å‚æ•°(workers=2, prefetch=1)ã€ç¡¬ä»¶é…ç½®å¯¹æ¯”(1å¡vs4å¡)",
            comparison_focus="æ‰¹å¤„ç†å¤§å°(64/128/256) Ã— è®­ç»ƒæ¨¡å¼(single/ddp) Ã— ç¡¬ä»¶é…ç½®(1å¡/4å¡)"
        )
        
        # å®éªŒç»„5ï¼šæµæ°´çº¿å¹¶è¡Œchunkså‚æ•°ä¼˜åŒ–
        groups[5] = ExperimentGroup(
            name="Pipeline Parallel Chunks Parameter Optimization",
            description="ä¸“é—¨é’ˆå¯¹æµæ°´çº¿å¹¶è¡Œæ¨¡å¼ï¼Œæµ‹è¯•ä¸åŒchunksè®¾ç½®(16/32/64)å¯¹è®­ç»ƒååé‡å’Œå†…å­˜æ•ˆç‡çš„å½±å“",
            config={
                'mode': ['pp'],
                'model': ['resnet50'],
                'batch_size': [128],
                'epochs': [30],
                'dataset': ['cifar100'],
                'gpu_ids': [[1, 2, 3, 5]],
                'num_workers': [2],
                'prefetch_factor': [1],
                'chunks': [16, 32, 64]
            },
            control_variables="è®­ç»ƒæ¨¡å¼(æµæ°´çº¿å¹¶è¡Œ)ã€æ¨¡å‹æ¶æ„(ResNet50)ã€ç¡¬ä»¶é…ç½®(4å¡)ã€æ‰¹å¤„ç†å¤§å°(128)ã€æ•°æ®åŠ è½½å‚æ•°",
            comparison_focus="æµæ°´çº¿å¹¶è¡Œchunkså‚æ•°: 16 vs 32 vs 64"
        )
        
        return groups
    
    def validate_params(self, params: Dict[str, Any]) -> bool:
        """éªŒè¯å‚æ•°ç»„åˆæ˜¯å¦æœ‰æ•ˆ"""
        mode = params['mode']
        num_gpus = len(params['gpu_ids'])
        
        # singleæ¨¡å¼åªèƒ½ä½¿ç”¨1ä¸ªGPU
        if mode == 'single' and num_gpus != 1:
            return False
        
        # dp, ddp, mp, ppæ¨¡å¼éœ€è¦è‡³å°‘2ä¸ªGPU
        if mode in ['dp', 'ddp', 'mp', 'pp'] and num_gpus < 2:
            return False
        
        if mode == 'hp' and num_gpus !=4:
            return False
        
        # éppæ¨¡å¼chunkså¿…é¡»ä¸º0
        if mode != 'pp' and params['chunks'] != 0:
            return False
        
        # ppæ¨¡å¼chunkså¿…é¡»å¤§äºç­‰äºGPUæ•°é‡
        if mode == 'pp' and params['chunks'] < num_gpus:
            return False
        
        return True
    
    def generate_experiment_name(self, params: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®éªŒåç§°ï¼ŒåŒ…å«æ‰€æœ‰å…³é”®å‚æ•°ä»¥ç¡®ä¿å”¯ä¸€æ€§"""
        name_parts = [
            params['mode'],
            params['model'],
            f"bs{params['batch_size']}",
            f"gpu{len(params['gpu_ids'])}"
        ]
        
        # å§‹ç»ˆåŒ…å«workeræ•°é‡ï¼Œå› ä¸ºè¿™æ˜¯é‡è¦çš„å¯¹æ¯”ç»´åº¦
        name_parts.append(f"nw{params['num_workers']}")

        # å§‹ç»ˆåŒ…å«chunkså‚æ•°ï¼Œç”¨äºåŒºåˆ†ä¸åŒå®éªŒ
        name_parts.append(f"chunks{params['chunks']}")
        
        return '_'.join(name_parts)
    
    def build_command(self, params: Dict[str, Any], checkpoint_path: str) -> List[str]:
        """æ„å»ºè®­ç»ƒå‘½ä»¤"""

        cmd = ['python', '-u', 'main.py']
        
        # æ·»åŠ æ‰€æœ‰è®­ç»ƒå‚æ•°
        for key, value in params.items():
            if key == 'gpu_ids':
                cmd.extend(['--gpu-ids', ','.join(map(str, value))])
            elif key == 'num_gpus':
                continue  # è¿™æ˜¯è®¡ç®—å¾—å‡ºçš„å‚æ•°ï¼Œä¸éœ€è¦ä¼ é€’
            elif isinstance(value, bool):
                if value:
                    cmd.append(f'--{key.replace("_", "-")}')
            elif value is not None:
                cmd.extend([f'--{key.replace("_", "-")}', str(value)])
        
        cmd.extend(['--final-checkpoint-path', checkpoint_path])
        return cmd
    
    def run_single_experiment(self, params: Dict[str, Any], exp_name: str, 
                            log_dir: str, checkpoint_dir: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        print(f"\nğŸš€ Running: {exp_name}")
        
        # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
        checkpoint_path = os.path.join(checkpoint_dir, f"{exp_name}.pth")
        log_file = os.path.join(log_dir, f"{exp_name}.log")
        
        # æ£€æŸ¥å®éªŒæ˜¯å¦å·²å®Œæˆï¼Œé¿å…é‡å¤è¿è¡Œ
        if os.path.exists(checkpoint_path):
            print(f"âš ï¸  Skipping existing experiment: {exp_name}")
            return {
                'experiment_name': exp_name,
                'params': params,
                'success': True,
                'skipped': True,
                'checkpoint_path': checkpoint_path,
                'log_file': log_file
            }
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = self.build_command(params, checkpoint_path)
        print(f"Command: {' '.join(cmd)}")
        
        start_time = time.time()
        
        try:
            with open(log_file, 'w', buffering=1) as f:
                # å†™å…¥å®éªŒå…ƒä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶
                f.write("="*100 + "\n")
                f.write(f"Experiment: {exp_name}\n")
                f.write(f"Parameters: {json.dumps(params, indent=2)}\n")
                f.write(f"Command: {' '.join(cmd)}\n")
                f.write(f"Start Time: {datetime.now().isoformat()}\n")
                f.write("="*100 + "\n\n")
                f.flush()
                
                # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    universal_newlines=True,
                    bufsize=1,
                    preexec_fn=None if sys.platform == 'win32' else os.setpgrp
                )
                
                # å®æ—¶è¾“å‡ºè®­ç»ƒæ—¥å¿—å¹¶ä¿å­˜åˆ°æ–‡ä»¶
                for line in process.stdout:
                    print(line, end='')
                    f.write(line)
                    f.flush()
                
                process.wait()
                return_code = process.returncode
            
            elapsed_time = time.time() - start_time
            success = return_code == 0 and os.path.exists(checkpoint_path)
            
            result = {
                'experiment_name': exp_name,
                'params': params,
                'success': success,
                'return_code': return_code,
                'elapsed_time': elapsed_time,
                'elapsed_time_str': f"{elapsed_time/3600:.2f}h",
                'checkpoint_path': checkpoint_path,
                'log_file': log_file,
                'timestamp': datetime.now().isoformat()
            }
            
            status = "âœ… Success" if success else "âŒ Failed"
            print(f"{status} - Time: {elapsed_time/3600:.2f}h")
            
            return result
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Error: {str(e)}")
            
            return {
                'experiment_name': exp_name,
                'params': params,
                'success': False,
                'error': str(e),
                'elapsed_time': elapsed_time,
                'checkpoint_path': checkpoint_path,
                'log_file': log_file,
                'timestamp': datetime.now().isoformat()
            }
    
    def run_experiment_group(self, group_id: int, custom_epochs: Optional[int] = None) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®éªŒç»„çš„æ‰€æœ‰å®éªŒ"""
        if group_id not in self.experiment_groups:
            raise ValueError(f"Experiment group {group_id} not found")
        
        group = self.experiment_groups[group_id]
        
        print("\n" + "="*100)
        print(f"ğŸ§ª EXPERIMENT GROUP {group_id}: {group.name}")
        print("="*100)
        print(f"ğŸ“ Description: {group.description}")
        print(f"ğŸ”§ Control Variables: {group.control_variables}")
        print(f"ğŸ¯ Comparison Focus: {group.comparison_focus}")
        print("="*100)
        
        # åˆ›å»ºå®éªŒç»„ä¸“ç”¨ç›®å½•ç»“æ„
        group_dir = os.path.join(self.base_dir, f"group_{group_id}_{group.get_safe_name()}")
        checkpoint_dir = os.path.join(group_dir, 'checkpoints')
        log_dir = os.path.join(group_dir, 'logs')
        
        os.makedirs(checkpoint_dir, exist_ok=True)
        os.makedirs(log_dir, exist_ok=True)
        
        # ä¿å­˜å®éªŒç»„é…ç½®ä¿¡æ¯
        info_file = os.path.join(group_dir, 'experiment_info.json')
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump({
                'group_id': group_id,
                'name': group.name,
                'description': group.description,
                'control_variables': group.control_variables,
                'comparison_focus': group.comparison_focus,
                'config': group.config,
                'created_at': datetime.now().isoformat()
            }, f, indent=2, ensure_ascii=False)
        
        # åº”ç”¨è‡ªå®šä¹‰epochsè®¾ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
        config = group.config.copy()
        if custom_epochs is not None:
            config['epochs'] = [custom_epochs]
            print(f"ğŸ”„ Using custom epochs: {custom_epochs}")
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å‚æ•°ç»„åˆ
        keys = list(config.keys())
        values = list(config.values())
        all_combinations = list(product(*values))
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„å‚æ•°ç»„åˆ
        valid_combinations = []
        for combination in all_combinations:
            params = dict(zip(keys, combination))
            params['num_gpus'] = len(params['gpu_ids'])
            
            if self.validate_params(params):
                valid_combinations.append(params)
        
        print(f"ğŸ“Š Total experiments in this group: {len(valid_combinations)}")
        
        # ä¾æ¬¡è¿è¡Œæ‰€æœ‰æœ‰æ•ˆå®éªŒ
        group_results = []
        for i, params in enumerate(valid_combinations, 1):
            exp_name = self.generate_experiment_name(params)
            print(f"\n[{i}/{len(valid_combinations)}] ", end="")
            
            result = self.run_single_experiment(params, exp_name, log_dir, checkpoint_dir)
            group_results.append(result)
            
            # å®æ—¶ä¿å­˜ä¸­é—´ç»“æœ
            results_file = os.path.join(group_dir, 'results.json')
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'group_info': {
                        'group_id': group_id,
                        'name': group.name,
                        'description': group.description,
                        'control_variables': group.control_variables,
                        'comparison_focus': group.comparison_focus
                    },
                    'total_experiments': len(valid_combinations),
                    'completed_experiments': i,
                    'results': group_results
                }, f, indent=2, ensure_ascii=False)
            
            # åˆ†å¸ƒå¼è®­ç»ƒåç­‰å¾…GPUèµ„æºå®Œå…¨é‡Šæ”¾
            if params['mode'] in ['dp', 'ddp', 'mp', 'pp']:
                time.sleep(5)
        
        # ç”Ÿæˆå®éªŒç»„è¯¦ç»†æ€»ç»“æŠ¥å‘Š
        self.generate_group_summary(group_id, group, group_results, group_dir)
        
        return {
            'group_id': group_id,
            'group_name': group.name,
            'total_experiments': len(valid_combinations),
            'successful_experiments': sum(1 for r in group_results if r['success']),
            'results': group_results,
            'group_dir': group_dir
        }
    
    def generate_group_summary(self, group_id: int, group: ExperimentGroup, 
                             results: List[Dict], group_dir: str):
        """ç”Ÿæˆå®éªŒç»„è¯¦ç»†æ€»ç»“æŠ¥å‘Š"""
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        total_time = sum(r.get('elapsed_time', 0) for r in results if not r.get('skipped', False))
        
        summary_file = os.path.join(group_dir, 'summary.md')
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# å®éªŒç»„ {group_id}: {group.name}\n\n")
            f.write(f"## å®éªŒæè¿°\n{group.description}\n\n")
            f.write(f"## æ§åˆ¶å˜é‡\n{group.control_variables}\n\n")
            f.write(f"## å¯¹æ¯”é‡ç‚¹\n{group.comparison_focus}\n\n")
            
            f.write("## å®éªŒç»Ÿè®¡\n")
            f.write(f"- æ€»å®éªŒæ•°: {len(results)}\n")
            f.write(f"- æˆåŠŸ: {successful}\n")
            f.write(f"- å¤±è´¥: {failed}\n")
            f.write(f"- æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶\n\n")
            
            f.write("## å®éªŒç»“æœè¯¦æƒ…\n")
            f.write("| å®éªŒåç§° | çŠ¶æ€ | è€—æ—¶ | å¤‡æ³¨ |\n")
            f.write("|---------|------|------|------|\n")
            
            for result in results:
                status = "âœ…" if result['success'] else "âŒ"
                if result.get('skipped'):
                    status = "â­ï¸"
                    time_str = "è·³è¿‡"
                else:
                    time_str = result.get('elapsed_time_str', 'N/A')
                
                note = ""
                if result.get('skipped'):
                    note = "å·²å­˜åœ¨"
                elif not result['success']:
                    note = result.get('error', 'å¤±è´¥')
                
                f.write(f"| {result['experiment_name']} | {status} | {time_str} | {note} |\n")
        
        print(f"\nğŸ“‹ Summary saved to: {summary_file}")
    
    def run_experiments(self, experiment_ids: List[int], custom_epochs: Optional[int] = None):
        """è¿è¡ŒæŒ‡å®šçš„å®éªŒç»„"""
        print("\n" + "ğŸ¯" * 50)
        print("åˆ†å¸ƒå¼è®­ç»ƒå¯¹æ¯”å®éªŒå¼€å§‹")
        print("ğŸ¯" * 50)
        
        if custom_epochs:
            print(f"ğŸ”„ ä½¿ç”¨è‡ªå®šä¹‰epochs: {custom_epochs}")
        
        all_results = {}
        
        for group_id in experiment_ids:
            if group_id not in self.experiment_groups:
                print(f"âš ï¸  Warning: Experiment group {group_id} not found, skipping...")
                continue
            
            try:
                result = self.run_experiment_group(group_id, custom_epochs)
                all_results[group_id] = result
                
                print(f"\nâœ… Group {group_id} completed: {result['successful_experiments']}/{result['total_experiments']} successful")
                
            except Exception as e:
                print(f"\nâŒ Error in group {group_id}: {str(e)}")
                import traceback
                traceback.print_exc()
        
        # ç”Ÿæˆè·¨å®éªŒç»„çš„æ€»ä½“åˆ†ææŠ¥å‘Š
        self.generate_overall_summary(all_results)
        
        print("\n" + "ğŸ‰" * 50)
        print("æ‰€æœ‰å®éªŒå®Œæˆï¼")
        print("ğŸ‰" * 50)
    
    def generate_overall_summary(self, all_results: Dict[int, Dict]):
        """ç”Ÿæˆè·¨å®éªŒç»„çš„æ€»ä½“åˆ†ææŠ¥å‘Š"""
        summary_file = os.path.join(self.base_dir, 'overall_summary.md')
        
        total_experiments = sum(r['total_experiments'] for r in all_results.values())
        total_successful = sum(r['successful_experiments'] for r in all_results.values())
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("# åˆ†å¸ƒå¼è®­ç»ƒå¯¹æ¯”å®éªŒæ€»ä½“æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æ€»ä½“ç»Ÿè®¡\n")
            f.write(f"- å®éªŒç»„æ•°: {len(all_results)}\n")
            f.write(f"- æ€»å®éªŒæ•°: {total_experiments}\n")
            f.write(f"- æˆåŠŸå®éªŒ: {total_successful}\n")
            f.write(f"- æˆåŠŸç‡: {total_successful/total_experiments*100:.1f}%\n\n")
            
            f.write("## å„å®éªŒç»„ç»“æœæ±‡æ€»\n")
            for group_id, result in all_results.items():
                group = self.experiment_groups[group_id]
                success_rate = result['successful_experiments'] / result['total_experiments'] * 100
                
                f.write(f"### å®éªŒç»„ {group_id}: {group.name}\n")
                f.write(f"- å®éªŒç›®æ ‡: {group.description}\n")
                f.write(f"- å¯¹æ¯”ç»´åº¦: {group.comparison_focus}\n")
                f.write(f"- å®éªŒæ•°é‡: {result['total_experiments']}\n")
                f.write(f"- æˆåŠŸæ•°é‡: {result['successful_experiments']}\n")
                f.write(f"- æˆåŠŸç‡: {success_rate:.1f}%\n")
                f.write(f"- ç»“æœç›®å½•: `{result['group_dir']}`\n\n")
            
            f.write("## å®éªŒè®¾è®¡è¯´æ˜\n")
            for group_id, group in self.experiment_groups.items():
                if group_id in all_results:
                    f.write(f"**å®éªŒç»„ {group_id}**: {group.comparison_focus}\n")
            
            f.write(f"\n## ç›®å½•ç»“æ„è¯´æ˜\n")
            f.write("```\n")
            f.write("experiments/\n")
            f.write("â”œâ”€â”€ overall_summary.md          # æ€»ä½“åˆ†ææŠ¥å‘Š\n")
            for group_id in all_results.keys():
                group = self.experiment_groups[group_id]
                f.write(f"â”œâ”€â”€ group_{group_id}_{group.get_safe_name()}/\n")
                f.write(f"â”‚   â”œâ”€â”€ experiment_info.json   # å®éªŒç»„é…ç½®ä¿¡æ¯\n")
                f.write(f"â”‚   â”œâ”€â”€ results.json          # è¯¦ç»†å®éªŒç»“æœæ•°æ®\n")
                f.write(f"â”‚   â”œâ”€â”€ summary.md            # å®éªŒç»„åˆ†ææŠ¥å‘Š\n")
                f.write(f"â”‚   â”œâ”€â”€ checkpoints/          # è®­ç»ƒå®Œæˆçš„æ¨¡å‹æ–‡ä»¶\n")
                f.write(f"â”‚   â””â”€â”€ logs/                 # è¯¦ç»†è®­ç»ƒæ—¥å¿—\n")
            f.write("```\n")
        
        print(f"\nğŸ“Š Overall summary saved to: {summary_file}")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='åˆ†å¸ƒå¼è®­ç»ƒå¯¹æ¯”å®éªŒ')
    
    parser.add_argument('--experiment', type=str, default='all',
                       help='å®éªŒç»„IDï¼Œæ”¯æŒ: all, 1, 2, 3, 4, 5 æˆ–ç»„åˆå¦‚ 1,3,5')
    
    parser.add_argument('--epochs', type=int, default=None,
                       help='è‡ªå®šä¹‰epochsæ•°é‡ï¼Œè¦†ç›–é»˜è®¤è®¾ç½®')
    
    parser.add_argument('--base-dir', type=str, default='./experiments',
                       help='å®éªŒåŸºç¡€ç›®å½•')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è§£æå®éªŒç»„IDå‚æ•°
    if args.experiment.lower() == 'all':
        experiment_ids = list(range(1, 6))  # 1-5 (ç°åœ¨åªæœ‰5ä¸ªå®éªŒç»„)
    else:
        try:
            experiment_ids = [int(x.strip()) for x in args.experiment.split(',')]
            # éªŒè¯å®éªŒç»„IDçš„æœ‰æ•ˆæ€§
            valid_ids = list(range(1, 6))
            for exp_id in experiment_ids:
                if exp_id not in valid_ids:
                    print(f"âŒ Invalid experiment ID: {exp_id}. Valid IDs: {valid_ids}")
                    return
        except ValueError:
            print(f"âŒ Invalid experiment format: {args.experiment}")
            print("Use: all, 1, 2, 3, 4, 5 or combinations like 1,3,5")
            return
    
    print("ğŸ§ª åˆ†å¸ƒå¼è®­ç»ƒå¯¹æ¯”å®éªŒ")
    print(f"ğŸ“ å®éªŒç›®å½•: {args.base_dir}")
    print(f"ğŸ¯ è¿è¡Œå®éªŒç»„: {experiment_ids}")
    if args.epochs:
        print(f"ğŸ”„ è‡ªå®šä¹‰epochs: {args.epochs}")
    
    # æ˜¾ç¤ºå°†è¦è¿è¡Œçš„å®éªŒç»„ä¿¡æ¯
    scheduler = TrainingScheduler(base_dir=args.base_dir)
    print("\nğŸ“‹ å®éªŒç»„åˆ—è¡¨:")
    for exp_id in experiment_ids:
        group = scheduler.experiment_groups[exp_id]
        print(f"  {exp_id}. {group.name}")
        print(f"     {group.comparison_focus}")
    
    # ç¡®è®¤å¼€å§‹å®éªŒ
    print(f"\næ€»è®¡å°†è¿è¡Œ {len(experiment_ids)} ä¸ªå®éªŒç»„")
    
    # å¼€å§‹æ‰§è¡Œæ‰€æœ‰å®éªŒ
    scheduler.run_experiments(experiment_ids, args.epochs)


if __name__ == '__main__':
    main()
